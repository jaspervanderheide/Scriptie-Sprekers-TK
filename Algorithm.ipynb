{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.sklearn_api.w2vmodel import W2VTransformer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'f1-scores': scores,\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"Handelingen.csv\", index_col=0)\n",
    "Partij = df.partij\n",
    "sbs = SnowballStemmer(\"dutch\")\n",
    "Tekst = df.tekst.apply(lambda x: ' '.join([sbs.stem(t) for t in tokenizer.tokenize(x)]))\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DOEN</th>\n",
       "      <th>RAW</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>PIPELINE</th>\n",
       "      <th>SGD__loss</th>\n",
       "      <th>MNB__alpha</th>\n",
       "      <th>KNB__n_neighbors</th>\n",
       "      <th>SGD__penalty</th>\n",
       "      <th>MLP__hidden_layer_sizes</th>\n",
       "      <th>MLP__solver</th>\n",
       "      <th>MLP__alpha</th>\n",
       "      <th>SVC__degree</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__min_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>SVM</td>\n",
       "      <td>[('vect',CountVectorizer(stop_words=stopwords....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['none', 'l2', 'l1', 'elasticnet']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(1,1),(1,2)]</td>\n",
       "      <td>[5,10,50,100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>LogisticClassifier</td>\n",
       "      <td>[('vect',CountVectorizer(stop_words=stopwords....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['none', 'l2', 'l1', 'elasticnet']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(1,1),(1,2)]</td>\n",
       "      <td>[5,10,50,100]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>[('vect',CountVectorizer(stop_words=stopwords....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0,0.5,1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>SVC</td>\n",
       "      <td>[('vect',CountVectorizer(stop_words=stopwords....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2,3]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "      <td>[('vect',CountVectorizer(stop_words=stopwords....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0001,0.0002]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   DOEN                 RAW  \\\n",
       "2        True  False                 SVM   \n",
       "0        True  False  LogisticClassifier   \n",
       "1        True  False       MultinomialNB   \n",
       "4        True  False                 SVC   \n",
       "5        True  False                 MLP   \n",
       "\n",
       "                                          Classifier  PIPELINE  SGD__loss  \\\n",
       "2  [('vect',CountVectorizer(stop_words=stopwords....       NaN        NaN   \n",
       "0  [('vect',CountVectorizer(stop_words=stopwords....       NaN        NaN   \n",
       "1  [('vect',CountVectorizer(stop_words=stopwords....       NaN  [0,0.5,1]   \n",
       "4  [('vect',CountVectorizer(stop_words=stopwords....       NaN        NaN   \n",
       "5  [('vect',CountVectorizer(stop_words=stopwords....       NaN        NaN   \n",
       "\n",
       "   MNB__alpha                    KNB__n_neighbors  SGD__penalty  \\\n",
       "2         NaN  ['none', 'l2', 'l1', 'elasticnet']           NaN   \n",
       "0         NaN  ['none', 'l2', 'l1', 'elasticnet']           NaN   \n",
       "1         NaN                                 NaN           NaN   \n",
       "4         NaN                                 NaN           NaN   \n",
       "5         NaN                                 NaN           NaN   \n",
       "\n",
       "   MLP__hidden_layer_sizes      MLP__solver MLP__alpha    SVC__degree  \\\n",
       "2                      NaN              NaN        NaN            NaN   \n",
       "0                      NaN              NaN        NaN  [(1,1),(1,2)]   \n",
       "1                      NaN              NaN        NaN            NaN   \n",
       "4                      NaN              NaN      [2,3]            NaN   \n",
       "5                      NaN  [0.0001,0.0002]        NaN            NaN   \n",
       "\n",
       "  vect__ngram_range   vect__min_df  \n",
       "2     [(1,1),(1,2)]  [5,10,50,100]  \n",
       "0     [5,10,50,100]            NaN  \n",
       "1               NaN            NaN  \n",
       "4               NaN            NaN  \n",
       "5               NaN            NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Models.tsv', sep ='\\t', index_col=0)\n",
    "df3 = df.loc[df.DOEN == True]\n",
    "models = {}\n",
    "for x,y in zip(df3.Classifier,df3.PIPELINE):\n",
    "    exec(compile(\"a=\"+y,'','exec'))\n",
    "    models[x] = Pipeline(a)    \n",
    "params = {}\n",
    "for clf in set(df3.Classifier):\n",
    "    test = df3.loc[df3.Classifier == clf]\n",
    "    test = test.loc[test.DOEN == True]\n",
    "    test = test.dropna(axis=1, how='all')\n",
    "    test= test.drop([col for col in test.columns if \"__\" not in col], axis =1)\n",
    "    test = test.to_dict(orient='list')\n",
    "    testdict = {}\n",
    "    for x,y in test.items():\n",
    "        exec(compile(\"a=\"+y[0],'','exec'))\n",
    "        testdict[x] = a   \n",
    "    params[clf] = testdict\n",
    "#rawdict = {x:y for x,y in zip(df3.Classifier,df3.RAW)}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,pipe in models.items():\n",
    "    gs = GridSearchCV(pipe, params[name], cv=5, scoring='f1_weighted')\n",
    "    gs.fit(Tekst, Partij)\n",
    "    rows = [row(name, gsc.cv_validation_scores, gsc.parameters) for gsc in gs.grid_scores_]\n",
    "    df2 = pd.concat(rows, axis=1).T\n",
    "    pd.concat([df2,pd.read_csv('Scores.csv', index_col=0)], ignore_index=True).sort_values(['mean_score'], ascending=False).to_csv('Scores.csv')\n",
    "    df.loc[df.Classifier==name,\"DOEN\"]=False\n",
    "    df.to_csv('Models.tsv', sep='\\t')\n",
    "    \n",
    "#https://stackoverflow.com/questions/46735847/save-best-params-in-gridsearch-in-a-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/36271413/pandas-merge-nearly-duplicate-rows-based-on-column-value?rq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-9541d2eedbae>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-9541d2eedbae>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    3\tTrue\tFalse\tW2V\t[('w2v', W2VTransformer()), ('SGD', SGDClassifier(loss='hinge'))]\t\t\t\t['none', 'l2', 'l1', 'elasticnet']\u001b[0m\n\u001b[1;37m     \t   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "3\tTrue\tFalse\tW2V\t[('w2v', W2VTransformer()), ('SGD', SGDClassifier(loss='hinge'))]\t\t\t\t['none', 'l2', 'l1', 'elasticnet']\t\t\t\t\t\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
