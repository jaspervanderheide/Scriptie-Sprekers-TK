{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sn\n",
    "from sklearn import datasets\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.sklearn_api.w2vmodel import W2VTransformer\n",
    "from gensim.sklearn_api.d2vmodel import D2VTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from ast import literal_eval\n",
    "import xlrd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'f1-scores': scores,\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"Handelingen.csv\", index_col=0)\n",
    "Partij = df.partij\n",
    "sbs = SnowballStemmer(\"dutch\")\n",
    "listTekst = df.tekst.apply(lambda x: [sbs.stem(t) for t in tokenizer.tokenize(x)])\n",
    "normalTekst = df.tekst.apply(lambda x: ' '.join([sbs.stem(t) for t in tokenizer.tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Models.xlsx', index_col=0)\n",
    "df3 = df.loc[df.DOEN == True]\n",
    "models = {}\n",
    "\n",
    "for x,y in zip(df3.Classifier,df3.PIPELINE):\n",
    "    exec(compile(\"a=\"+y,'','exec'))\n",
    "    models[x] = Pipeline(a)    \n",
    "params = {}\n",
    "\n",
    "for clf in set(df3.Classifier):\n",
    "    test = df3.loc[df3.Classifier == clf]\n",
    "    test = test.loc[test.DOEN == True]\n",
    "    test = test.dropna(axis=1, how='all')\n",
    "    test= test.drop([col for col in test.columns if \"__\" not in col], axis =1)\n",
    "    test = test.to_dict(orient='list')\n",
    "    testdict = {}\n",
    "    for x,y in test.items():\n",
    "        a=literal_eval(y[0])\n",
    "        #exec(compile(\"a=\"+y[0],'','exec'))\n",
    "        testdict[x] = a   \n",
    "    params[clf] = testdict\n",
    "rawdict = {x:y for x,y in zip(df3.Classifier,df3.RAW)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,pipe in models.items():\n",
    "    if rawdict[name]:\n",
    "         Tekst = list(listTekst)\n",
    "    else:\n",
    "        Tekst = list(normalTekst)\n",
    "    gs = GridSearchCV(pipe, params[name], cv=5, scoring='f1_weighted')\n",
    "    gs.fit(Tekst, Partij)\n",
    "    rows = [row(name, gsc.cv_validation_scores, gsc.parameters) for gsc in gs.grid_scores_]\n",
    "    df2 = pd.concat(rows, axis=1).T\n",
    "    pd.concat([df2,pd.read_csv('Scores.csv', index_col=0)], ignore_index=True).sort_values(['mean_score'], ascending=False).to_csv('Scores.csv')\n",
    "    df.loc[df.Classifier==name,\"DOEN\"]=False\n",
    "    df.to_excel('Models.xlsx')\n",
    "    \n",
    "#https://stackoverflow.com/questions/46735847/save-best-params-in-gridsearch-in-a-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/36271413/pandas-merge-nearly-duplicate-rows-based-on-column-value?rq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
