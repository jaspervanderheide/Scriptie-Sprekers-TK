{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.sbs = SnowballStemmer(\"dutch\")\n",
    "    def __call__(self, doc):\n",
    "        return [self.sbs.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172676\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achternaam</th>\n",
       "      <th>partij</th>\n",
       "      <th>tekst</th>\n",
       "      <th>file</th>\n",
       "      <th>datum</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107136</th>\n",
       "      <td>Wilders</td>\n",
       "      <td>PVV</td>\n",
       "      <td>\\r\\n           \\r\\n             Mevrouw de voo...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107137</th>\n",
       "      <td>Roemer</td>\n",
       "      <td>SP</td>\n",
       "      <td>\\r\\n           \\r\\n             Voorzitter. Vo...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107138</th>\n",
       "      <td>Pechtold</td>\n",
       "      <td>D66</td>\n",
       "      <td>\\r\\n           \\r\\n             Voorzitter. Tw...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107139</th>\n",
       "      <td>Van Haersma Buma</td>\n",
       "      <td>CDA</td>\n",
       "      <td>\\r\\n           \\r\\n             Voorzitter. Al...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107141</th>\n",
       "      <td>Van Haersma Buma</td>\n",
       "      <td>CDA</td>\n",
       "      <td>\\r\\n           \\r\\n             Dan het sociaa...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              achternaam partij  \\\n",
       "107136           Wilders    PVV   \n",
       "107137            Roemer     SP   \n",
       "107138          Pechtold    D66   \n",
       "107139  Van Haersma Buma    CDA   \n",
       "107141  Van Haersma Buma    CDA   \n",
       "\n",
       "                                                    tekst  \\\n",
       "107136  \\r\\n           \\r\\n             Mevrouw de voo...   \n",
       "107137  \\r\\n           \\r\\n             Voorzitter. Vo...   \n",
       "107138  \\r\\n           \\r\\n             Voorzitter. Tw...   \n",
       "107139  \\r\\n           \\r\\n             Voorzitter. Al...   \n",
       "107141  \\r\\n           \\r\\n             Dan het sociaa...   \n",
       "\n",
       "                           file       datum  \\\n",
       "107136  h-tk-20122013-100-3.xml  2013-06-26   \n",
       "107137  h-tk-20122013-100-3.xml  2013-06-26   \n",
       "107138  h-tk-20122013-100-3.xml  2013-06-26   \n",
       "107139  h-tk-20122013-100-3.xml  2013-06-26   \n",
       "107141  h-tk-20122013-100-3.xml  2013-06-26   \n",
       "\n",
       "                                                    tags  \n",
       "107136  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107137  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107138  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107139  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107141  ['Bestuur | Parlement', 'Financiën | Begroting']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Handelingen.csv\", index_col=0)\n",
    "Partij = df.partij\n",
    "print(len(df))\n",
    "Tekst = CountVectorizer(tokenizer=StemTokenizer(),stop_words=stopwords.words('dutch'), ngram_range=(1,2)).fit_transform(df.tekst)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/46735847/save-best-params-in-gridsearch-in-a-pandas-dataframe\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticClassifier': {'SGD__penalty': ['none', 'l2', 'l1', 'elasticnet']},\n",
       " 'MultinomialNB': {'MNB__alpha': [0, 0.5, 1]},\n",
       " 'SVM': {'SGD__penalty': ['none', 'l2', 'l1', 'elasticnet']}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Models.tsv', sep ='\\t', index_col=0)\n",
    "models = {}\n",
    "for x,y in zip(df.Classifier,df.PIPELINE):\n",
    "    exec(compile(\"a=\"+y,'','exec'))\n",
    "    models[x] = Pipeline(a)    \n",
    "params = {}\n",
    "for clf in set(df.Classifier):\n",
    "    test = df.loc[df.Classifier == clf]\n",
    "    test = test.dropna(axis=1, how='all').drop([\"PIPELINE\",\"Classifier\"], axis =1)\n",
    "    test = test.to_dict(orient='list')\n",
    "    testdict = {}\n",
    "    for x,y in test.items():\n",
    "        exec(compile(\"a=\"+y[0],'','exec'))\n",
    "        testdict[x] = a   \n",
    "    params[clf] = testdict\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LogisticClassifier.\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for MultinomialNB.\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for SVM.\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    }
   ],
   "source": [
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(Tekst, Partij, scoring='f1_weighted', cv=5)\n",
    "\n",
    "scoresdf = helper.score_summary()\n",
    "scoresdf.to_csv(\"Scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull\n",
    "!git add Algorithm.ipynb\n",
    "!git add Scores.csv\n",
    "!git add Models.tsv\n",
    "!git commit -m Algorithm.ipynb\n",
    "!git commit -m Scores.csv\n",
    "!git commit -m Models.tsv\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
