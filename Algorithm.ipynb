{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.sbs = SnowballStemmer(\"dutch\")\n",
    "    def __call__(self, doc):\n",
    "        return [self.sbs.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achternaam</th>\n",
       "      <th>partij</th>\n",
       "      <th>tekst</th>\n",
       "      <th>file</th>\n",
       "      <th>datum</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107136</th>\n",
       "      <td>Wilders</td>\n",
       "      <td>PVV</td>\n",
       "      <td>Mevrouw de voorzitter. Dit kabinet heeft ons m...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107137</th>\n",
       "      <td>Roemer</td>\n",
       "      <td>SP</td>\n",
       "      <td>Voorzitter. Vorige week plaatsten werkgevers, ...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107138</th>\n",
       "      <td>Pechtold</td>\n",
       "      <td>D66</td>\n",
       "      <td>Voorzitter. Twee maanden geleden kreeg dit kab...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107139</th>\n",
       "      <td>Van Haersma Buma</td>\n",
       "      <td>CDA</td>\n",
       "      <td>Voorzitter. Alleen al in de eerste drie maande...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107141</th>\n",
       "      <td>Van Haersma Buma</td>\n",
       "      <td>CDA</td>\n",
       "      <td>Dan het sociaal akkoord. De voorzitter van MKB...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              achternaam partij  \\\n",
       "107136           Wilders    PVV   \n",
       "107137            Roemer     SP   \n",
       "107138          Pechtold    D66   \n",
       "107139  Van Haersma Buma    CDA   \n",
       "107141  Van Haersma Buma    CDA   \n",
       "\n",
       "                                                    tekst  \\\n",
       "107136  Mevrouw de voorzitter. Dit kabinet heeft ons m...   \n",
       "107137  Voorzitter. Vorige week plaatsten werkgevers, ...   \n",
       "107138  Voorzitter. Twee maanden geleden kreeg dit kab...   \n",
       "107139  Voorzitter. Alleen al in de eerste drie maande...   \n",
       "107141  Dan het sociaal akkoord. De voorzitter van MKB...   \n",
       "\n",
       "                           file      datum  \\\n",
       "107136  h-tk-20122013-100-3.xml 2013-06-26   \n",
       "107137  h-tk-20122013-100-3.xml 2013-06-26   \n",
       "107138  h-tk-20122013-100-3.xml 2013-06-26   \n",
       "107139  h-tk-20122013-100-3.xml 2013-06-26   \n",
       "107141  h-tk-20122013-100-3.xml 2013-06-26   \n",
       "\n",
       "                                                    tags  \n",
       "107136  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107137  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107138  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107139  ['Bestuur | Parlement', 'Financiën | Begroting']  \n",
       "107141  ['Bestuur | Parlement', 'Financiën | Begroting']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Handelingen.csv\", index_col=0)\n",
    "df = df.dropna()\n",
    "#https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "mask = (df['datum'] > '2012-11-05') & (df['datum'] <= '2017-03-23')\n",
    "df = df.loc[mask]\n",
    "df = df[df['partij'].isin(['50PLUS', 'CDA','ChristenUnie','D66','GroenLinks','PVV','PvdA','PvdD','SGP','SP','VVD'])]\n",
    "Partij = df.partij\n",
    "print(len(df))\n",
    "Tekst = CountVectorizer(tokenizer=StemTokenizer(),stop_words=stopwords.words('dutch'), ngram_range=(1,2)).fit_transform(df.tekst)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/46735847/save-best-params-in-gridsearch-in-a-pandas-dataframe\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticClassifier': {'SGD__penalty': ['none', 'l2', 'l1', 'elasticnet']},\n",
       " 'MultinomialNB': {'MNB__alpha': [0, 0.5, 1]},\n",
       " 'SVM': {'SGD__penalty': ['none', 'l2', 'l1', 'elasticnet']}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Models.tsv', sep ='\\t', index_col=0)\n",
    "models = {}\n",
    "for x,y in zip(df.Classifier,df.PIPELINE):\n",
    "    exec(compile(\"a=\"+y,'','exec'))\n",
    "    models[x] = Pipeline(a)    \n",
    "params = {}\n",
    "for clf in set(df.Classifier):\n",
    "    test = df.loc[df.Classifier == clf]\n",
    "    test = test.dropna(axis=1, how='all').drop([\"PIPELINE\",\"Classifier\"], axis =1)\n",
    "    test = test.to_dict(orient='list')\n",
    "    testdict = {}\n",
    "    for x,y in test.items():\n",
    "        exec(compile(\"a=\"+y[0],'','exec'))\n",
    "        testdict[x] = a   \n",
    "    params[clf] = testdict\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LogisticClassifier.\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for MultinomialNB.\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   55.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for SVM.\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(Tekst, Partij, scoring='f1_weighted', cv=2)\n",
    "\n",
    "scoresdf = helper.score_summary()\n",
    "scoresdf.to_csv(\"Scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>MNB__alpha</th>\n",
       "      <th>SGD__penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.340556</td>\n",
       "      <td>0.344019</td>\n",
       "      <td>0.347482</td>\n",
       "      <td>0.00346291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.314872</td>\n",
       "      <td>0.31896</td>\n",
       "      <td>0.323048</td>\n",
       "      <td>0.00408798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticClassifier</td>\n",
       "      <td>0.30126</td>\n",
       "      <td>0.302487</td>\n",
       "      <td>0.303714</td>\n",
       "      <td>0.00122703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.26585</td>\n",
       "      <td>0.267044</td>\n",
       "      <td>0.268238</td>\n",
       "      <td>0.00119409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.240791</td>\n",
       "      <td>0.240808</td>\n",
       "      <td>0.240825</td>\n",
       "      <td>1.67727e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticClassifier</td>\n",
       "      <td>0.237929</td>\n",
       "      <td>0.239958</td>\n",
       "      <td>0.241987</td>\n",
       "      <td>0.00202891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticClassifier</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>0.218458</td>\n",
       "      <td>0.221285</td>\n",
       "      <td>0.0028271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticClassifier</td>\n",
       "      <td>0.209787</td>\n",
       "      <td>0.214837</td>\n",
       "      <td>0.219887</td>\n",
       "      <td>0.0050501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.18685</td>\n",
       "      <td>0.189328</td>\n",
       "      <td>0.191806</td>\n",
       "      <td>0.00247772</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.170105</td>\n",
       "      <td>0.172166</td>\n",
       "      <td>0.174228</td>\n",
       "      <td>0.00206138</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.142121</td>\n",
       "      <td>0.147116</td>\n",
       "      <td>0.152111</td>\n",
       "      <td>0.00499468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             estimator min_score mean_score max_score    std_score MNB__alpha  \\\n",
       "8                  SVM  0.340556   0.344019  0.347482   0.00346291        NaN   \n",
       "7                  SVM  0.314872    0.31896  0.323048   0.00408798        NaN   \n",
       "0   LogisticClassifier   0.30126   0.302487  0.303714   0.00122703        NaN   \n",
       "10                 SVM   0.26585   0.267044  0.268238   0.00119409        NaN   \n",
       "4        MultinomialNB  0.240791   0.240808  0.240825  1.67727e-05          0   \n",
       "1   LogisticClassifier  0.237929   0.239958  0.241987   0.00202891        NaN   \n",
       "3   LogisticClassifier  0.215631   0.218458  0.221285    0.0028271        NaN   \n",
       "2   LogisticClassifier  0.209787   0.214837  0.219887    0.0050501        NaN   \n",
       "5        MultinomialNB   0.18685   0.189328  0.191806   0.00247772        0.5   \n",
       "6        MultinomialNB  0.170105   0.172166  0.174228   0.00206138          1   \n",
       "9                  SVM  0.142121   0.147116  0.152111   0.00499468        NaN   \n",
       "\n",
       "   SGD__penalty  \n",
       "8            l2  \n",
       "7          none  \n",
       "0          none  \n",
       "10   elasticnet  \n",
       "4           NaN  \n",
       "1            l2  \n",
       "3    elasticnet  \n",
       "2            l1  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "9            l1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in Algorithm.ipynb.\n",
      "The file will have its original line endings in your working directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master e885d2e] Algorithm.ipynb\n",
      " 3 files changed, 263 insertions(+), 79 deletions(-)\n",
      " rewrite Models.tsv (86%)\n",
      " rewrite Scores.csv (100%)\n",
      "On branch master\n",
      "Your branch is ahead of 'origin/master' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "\tmodified:   Scraper.ipynb\n",
      "\n",
      "Untracked files:\n",
      "\t.ipynb_checkpoints/\n",
      "\tDataInfo.ipynb\n",
      "\tHandelingen.csv\n",
      "\tHandelingenTK/\n",
      "\tHandelingenTKmeta/\n",
      "\tLiteratuur/\n",
      "\tScraper.md\n",
      "\tUntitled.ipynb\n",
      "\n",
      "no changes added to commit\n",
      "On branch master\n",
      "Your branch is ahead of 'origin/master' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "\tmodified:   Scraper.ipynb\n",
      "\n",
      "Untracked files:\n",
      "\t.ipynb_checkpoints/\n",
      "\tDataInfo.ipynb\n",
      "\tHandelingen.csv\n",
      "\tHandelingenTK/\n",
      "\tHandelingenTKmeta/\n",
      "\tLiteratuur/\n",
      "\tScraper.md\n",
      "\tUntitled.ipynb\n",
      "\n",
      "no changes added to commit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/jaspervdh96/Scriptie-Sprekers-TK.git\n",
      "   2be15fc..e885d2e  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git pull\n",
    "!git add Algorithm.ipynb\n",
    "!git add Scores.csv\n",
    "!git add Models.tsv\n",
    "!git commit -m Algorithm.ipynb\n",
    "!git commit -m Scores.csv\n",
    "!git commit -m Models.tsv\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
