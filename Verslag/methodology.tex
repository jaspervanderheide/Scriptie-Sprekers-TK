\section{Methodologie}
\label{sec:meth}


\subsection{De data}
\label{data}
De data die gebruikt zijn, zijn de Handelingen van de Tweede Kamer gedurende het missionaire kabinet-Rutte II (5 november 2012 tot 22 maart 2017). Er was gekozen voor dit kabinet, omdat de data hiervoor makkelijk verkrijgbaar was, het kabinet lang zat - waardoor er veel data is - en het recent is waardoor het makkelijker te interpreteren is. In dit kabinet zaten de PvdA en VVD. Deze data zijn in xml-formaat van de website officielebekendmakingen.nl gehaald samen met bijbehorende metadatabestanden. De bestanden van de Handelingen bevatten voornamelijk informatie over spreekbeurten tijdens een debat, waaronder naam van een spreker, partij-affiliatie, inhoud van de spreekbeurt en het soort spreekbeurt.\par
Deze dataset bestaat uit een aantal soorten spreekbeurten; debatbijdragen, interrupties en antwoorden. Een debatbijdrage is de eerste onafgebroken spreekbeurt die een spreker geeft achter een spreekgestoelte, aangeduid in de xml-file met het attribuut \textit{nieuw="ja"}. Dit kan een bijdrage in een debat zijn of een vraag tijdens een vragenuur. Interrupties zijn de vragen die andere Kamerleden stellen vanachter de interruptiemicrofoon aan een spreker. Een antwoord zijn vervolgens de reactie van een spreker achter het spreekgestoelte op een interruptie. Aangezien een debatbijdrage geïnterrumpeerd kan worden, kan deze inhoudelijk doorlopen in een antwoord van een spreker. Vergelijkbare onderzoeken voegden vaak alle teksten van een spreker samen tot één document. Dit was alleen niet mogelijk voor dit onderzoek met de hoeveelheid kleine partijen in de Tweede Kamer. Deze zijn dan niet altijd in een training of test set zijn vertegenwoordigd. Daarom was in dit onderzoek ervoor gekozen om een debatbijdrage samengevoegd met alle bijbehorende antwoorden te beschouwen als één document.\par
Daarnaast zijn er verschillende soorten sprekers; de voorzitter, Tweede Kamerleden, leden van het kabinet en gastsprekers. Hieruit was alleen gekozen voor sprekers waarvan er een partij-affiliatie vermeld staat. Dit was niet het geval voor leden van het kabinet, de voorzitter en gastsprekers met uitzondering van Nederlandse leden van het Europees Parlement.\par
Deze dataset bevatte vervolgens naast de verkozen partijen na de Tweede Kamerverkiezingen van 2012 ook afsplitsingen van die partijen (tien in totaal) en bezoeken van vertegenwoordigingen van Nederlandse partijen uit het Europees Parlement (tien in totaal). Omdat er van beide categorieën relatief weinig data was en er overlap zat met hun oorspronkelijke of gelieerde partij, waren deze er uit gehaald. 50PLUS is in 2014 \cite{50PLUSNRC} uiteengevallen in twee fracties die aanspraak maakten op de partij-affiliatie 50PLUS. Vanaf dit moment zijn deze documenten niet meer meegenomen om onduidelijkheid te voorkomen.\par

De documenten verschilden in grootte (aantal woorden). De distributie van documentgrootte lijkt op een lognormale verdeling, maar met een Kolmogorov-Smirnov toets ($\alpha$ is 0.01) was hier geen bewijs voor gevonden \cite{Scipy}.

\begin{figure}[H]
    \centering
    \hspace*{-1in}
    \subfloat[Normale x-as]{{\includegraphics[width=9cm]{Verslag/Tables/lengthtexts.png} }}%
    \subfloat[Logaritmische x-as]{{\includegraphics[width=9cm]{Verslag/Tables/lengthtextslog.png} }}%
    \caption{Aantal woorden per document}%
    \label{fig:example}%
\end{figure}
Om toch de uitschieters er uit te halen, was aangenomen dat de distributie wel lognormaal verdeeld is en waren daarmee de documenten buiten het betrouwbaarheidsinterval van 95\% eruit gehaald. De documenten met een lengte van minimaal 28 en maximaal 1492 woorden bleven daarmee over. De gemiddelde documentlengte is daarna 498 woorden en de mediaan is 386 woorden.\par

\begin{table}[H]
\label{aantallen}
\caption{Aantal documenten per partij gedurende het missionaire kabinet-Rutte II.}
\centering
\input{Handmatig/Spreekbeurten.tex}
\end{table}
Deze 14899 documenten zijn verdeeld over 2984 debatten. Elke vraag tijdens het vragenuur als één debat gezien wordt. Op basis van deze aantallen is er voor classificatie een baseline nauwkeurigheid van 0.15 (door altijd grootste partij te kiezen) en baseline $F_1$ score van 0.11 (door te gokken gewogen bij aantal documenten van een partij).\par


\subsection{Methoden}


\subsubsection{DV1: Beste classificatiemethode}
Om deze deelvraag te beantwoorden zijn een aantal classificatiemethoden vergeleken. Aangezien het niet mogelijk was voor dit onderzoek om alle classificatiemethoden te vergelijken, beperkte dit onderzoek zich tot classificatiemethoden die gebruikt zijn in vergelijkbare onderzoeken, zoals besproken in sectie \ref{sec:Deelvraag1}. Er was voor gekozen om alleen gebruik te maken van methoden waarvan reeds implementaties beschikbaar waren in scikit-learn. Voor alle methoden werd gezocht naar de beste parameters, ook wel bekend als een grid search. Deze grid search werd gedaan door vijfmaal kruisvalidatie (\textit{cross-validation}), waarbij de training set steeds 80\% was en de test set 20\% van de totale dataset. Een totaal aantal van 6480 combinaties van methoden en parameters zijn getest. De verwachting was dat de scores lager zijn dan die gevonden in het gerelateerd werk, omdat de documentgrootte kleiner is en de baseline scores lager zijn.

\paragraph{Pre-processing}
Voor pre-processing is gebruik gemaakt van tokenisation en lowercasing. Voor tokenisation is de reguliere expressie $\\w+$ gebruikt, waardoor alles behalve letters en cijfers weggehaald wordt. Ook is er gevarieerd tussen wel of geen gebruik maken van stemming. In het geval van stemming is gebruik gemaakt van de Snowball Stemmer van de Python NLTK module.

\paragraph{Bag-of-words model}
Bag-of-words model is de meest gebruikte representatie van data in vergelijkbare onderzoeken. Deze is daarom ook gebruikt in dit onderzoek. Bij het bag-of-words model wordt elk document gerepresenteerd als een vector, waarbij elke kolom een woord is met een bijbehorende waarde. Voornaamste beperking van dit model is dat het geen rekening houdt met de volgorde van woorden, wat een groot effect kan hebben op de betekenis van een document.\par
Voor dit onderzoek waren de volgende wegingen voor woorden getest: \textit{boolean} (wel of niet aanwezig), \textit{tf} (woordfrequentie), \textit{tf-norm} (woordfrequentie genormaliseerd door documentlengte) en \textit{tf-idf} (woordfrequentie gecompenseerd voor documentfrequentie). Daarnaast werd in dit onderzoek geëxperimenteerd met een minimale of maximale woord- of documentfrequentie. Ook is gekeken naar het effect van combinaties van de volgende n-grams; unigrams, bigrams en trigrams. N-grams zijn combinaties van N aantal opeenvolgende woorden. Bij een unigram is elke feature gewoon één woord, terwijl bij een bigram dit twee opvolgende woorden zijn. Dit kan van belang zijn, want als bijvoorbeeld het woord \textit{asfalt} er in voorkomt, dan is het voor ideologie mogelijk relevant of er \textit{minder asfalt} of \textit{meer asfalt} staat.\par

\paragraph{Support Vector Machine en Logistische Regressie}
De meest voorkomende techniek in vergelijkbaar onderzoek is Support Vector Machine (SVM). Een andere techniek die gebruikt wordt, is logistische regressie. Beide hebben een eigen implementatie in scikit-learn, maar deze implementaties zijn niet efficiënt met grote datasets. Om deze reden is er in beide gevallen voor gekozen om gebruik te maken van de functie SGDClassifier, die beide technieken leert met \textit{stochastic gradient descent learning}. Voor regularisatie was hier geëxperimenteerd met L1 en L2 regularisatie en een combinatie van beide genaamd Elasticnet. De andere parameters zijn gelaten op de standaardwaarden van scikit-learn \cite{scikit-learn}. Een belangrijke onaangepaste waarde was die van maximaal aantal iteraties, waarvoor de scikit-learn standaard 5 is. Volgens scikit-learn convergeert de SGDClassifier rond de $10^{6}/n$ iteraties waar $n$ het aantal documenten in de training set is. In het geval van deze dataset zou dat 84 iteraties zijn. Vanwege de grootte van de grid search was het voor dit onderzoek niet mogelijk het maximaal aantal iteraties te verhogen tijdens de grid search. De resultaten buiten de grid search zullen gebaseerd zijn op een maximaal aantal iteraties van 100.\par
% https://towardsdatascience.com/how-to-make-sgd-classifier-perform-as-well-as-logistic-regression-using-parfit-cc10bca2d3c4

\paragraph{Naive Bayes}
Een andere techniek die gebruikt wordt voor politieke tekstclassificatie is Naive Bayes. Dit algoritme neemt aan dat elke \textit{feature} onafhankelijk is ten op zichte van de rest. Dit is bij tekstclassificatie vaak niet het geval omdat het gebruik van sommige woorden gepaard kan gaan met het gebruik van andere woorden. Daarnaast is het gebruik van meerdere n-grams in een classificatie schending van de aanname, want als bijvoorbeeld een bigram er in voorkomt dan komen ook beide unigrams er in voor. Desalniettemin blijkt Naive Bayes effectief te zijn voor tekstclassificatie \cite{bhand,scikit-learn}. Hiervoor zijn de functies van scikit-learn MultinomialNB en BernoulliNB gebruikt \cite{bhand,scikit-learn}.\par

\paragraph{Beoordelen van kwaliteit}
De meest gebruikte methoden om kwaliteit van politieke tekstclassificatie te beoordelen zijn nauwkeurigheid en $F_1$ score, die opgebouwd is uit sensitiviteit en precisie. Deze scores worden berekend op basis van vier hoeveelheden van mogelijke resultaten van een classificatie. Deze resultaten geven weer hoeveel documenten wel of niet bij een partij horen, en of deze wel of niet als dusdanig zijn geclassificeerd \cite{Manning:2008:IIR:1394399} .\par

\begin{table}[H]
\label{tab:scores}
\centering
\caption{Mogelijke resultaten van een classificatie.}
\begin{tabular}{l|l|l}
 & Behorend tot partij & Niet behorend tot partij\\ \hline
Geclassificeerd als partij &   \textit{true positive (tp)} & \textit{false positive (fp)} \\ \hline
Niet geclassificeerd als partij & \textit{false negative (fn)} & \textit{true negative (tn)} \\
\end{tabular}
\end{table}
\begin{equation}
    Precisie = \frac{tp}{tp + fp}\\
\end{equation}
\begin{equation}
    Sensitiviteit = \frac{tp}{tp + tn}
\end{equation}
\begin{equation}
    Nauwkeurigheid = \frac{tp + tn}{tp + tn + fp + fn}
\end{equation}
\begin{equation}
    F_1 = 2 * \frac{Precisie * Sensitiviteit}{Precisie + Sensitiviteit}
\end{equation}
Nauwkeurigheid (\textit{accuracy}) is het percentage van documenten dat correct geclassificeerd is. Nauwkeurigheid wordt voor de hele classificatie gedaan en niet per partij. Precisie (\textit{precision}) is het percentage van documenten geclassificeerd als een partij, dat ook bij die partij hoort. Sensitiviteit (\textit{recall}) is het percentage documenten van documenten behorende tot een partij, dat ook als die partij geclassificeerd is. $F_1$ is het harmonisch gemiddelde van sensitiviteit en precisie. Precisie, sensitiviteit en daarmee $F_1$ worden per partij berekend. Er zijn drie varianten om deze scores voor de hele classificatie te berekenen. \par
Allereerst is er micro, waarbij alle hoeveelheden van mogelijke resultaten bij elkaar opgeteld worden en vervolgens de scores berekend. Dit leidt ertoe dat resultaten van partijen met veel documenten belangrijker zijn. Als een classificatie kleine partijen grotendeels fout classificeert, kan deze score alsnog hoog zijn. In het geval van meer dan twee partijen is dit hetzelfde als nauwkeurigheid.\par 
Als tweede is er macro, waarbij alle scores per partij berekend worden en daarvan het gemiddelde wordt genomen. Dit leidt er dan weer toe dat resultaten van partijen met weinig documenten net zo belangrijk zijn. Hierdoor kan een classificatie met een laag aantal correct geclassificeerde documenten hoog scoren door vooral kleine partijen goed te classificeren.\par
Als laatste is er gewogen. Hierbij wordt net als macro de scores per partij berekend, maar neemt hiervan het gemiddelde gewogen bij het aantal documenten behorend tot een partij. Deze wijkt weinig af van de micro variant, tenzij er uitschieters zijn bij partijen.\par
Aangezien micro al terugkomt in nauwkeurigheid en het nadeel van macro te groot is omdat de partijen nogal variëren in grootte, was gekozen voor gewogen $F_1$ score naast nauwkeurigheid.

\subsubsection{DV2: Invloed van namen}
In Diermeier et al. \cite{diermeier_godbout_yu_kaufmann_2012} werd aangenomen dat namen een groot effect hebben op de classificatie. Hirst et al. \cite{Hirst_textto} bevestigden dit voor het Europees Parlement. Aangezien hier bij deelvraag 1 niet voor was gekozen, is bij deze deelvraag gekeken hoe groot het effect hiervan is. Op basis van vergelijkbaar onderzoek is de hypothese dat de achternamen van Kamerleden en partijnamen van invloed zijn.\par
Voor deze deelvraag werd wederom een classificatie gedaan met de classificatiemethode die resulteerde uit deelvraag 1. In deze classificatie werden alle partijnamen vervangen door \textit{PARTIJNAAM} en alle achternamen van Kamerleden vervangen door \textit{KAMERLIDNAAM}. Deze namen waren uit de Handelingen van de Tweede Kamer gehaald. Voor partijnamen waren ook lidwoorden toegevoegd en voor achternamen van Kamerleden zijn ook verkortingen meegenomen. Dit laatste omdat bijvoorbeeld \textit{Van Haersma Buma} vaak aangesproken wordt als \textit{Buma}. Voornamen van Kamerleden worden zelden tot nooit gebruikt, dus die waren er niet uitgehaald. Een nadeel van deze aanpak is dat ook namen van niet-Kamerleden of andere woorden weggehaald kunnen worden als deze hetzelfde zijn als naam van een Kamerlid. Door gebruik van gevoeligheid voor hoofdletters was geprobeerd dit te voorkomen. Een opvallend voorbeeld hiervan is de naam Rutte, die zowel behoort tot het Kamerlid Arno Rutte als de premier Mark Rutte. Steekproefgewijs was gekeken of er nog namen achter zijn gebleven, maar die waren niet gevonden. \par
Ook werd gekeken naar classificatie met alleen partijnamen en achternamen van Kamerleden. Alle andere woorden worden weggehaald. Namen van Kamerleden en partijen die niet aan elkaar geschreven worden, zoals \textit{Partij van de Arbeid}, zijn aan elkaar geschreven zodat het één feature is. Doordat alle andere woorden weggehaald zijn, waren de bi- en trigrams combinaties van namen die zinnen uit elkaar kunnen staan. Deze voegen daarom inhoudelijk niet meer informatie toe dan unigrams. Daarom werd er gebruikt van de classificatiemethode uit deelvraag 1, maar met alleen unigrams.\par
Op basis van de hypothese is de verwachting dat voor de classificatie zonder namen de scores een stuk lager zijn dan deelvraag 1 en de scores van de classificatie met alleen namen aanzienlijk hoger zijn dan de baseline scores.

\subsubsection{DV3: Oppositie of regering}
Om deze deelvraag te beantwoorden zijn drie experimenten uitgevoerd. Twee daarvan zijn gebaseerd op experimenten uit Hirst et al. \cite{Hirst_textto} voor dezelfde vraag. De derde is ontwikkeld voor dit onderzoek. Met deze laatste wordt begonnen. Bij deze deelvraag is de classificatiemethode uit deelvraag 1 zonder achternamen van Kamerleden en partijnamen gebruikt.\par
Als er een afhankelijkheid is van partij-status, dan is het te wachten dat het aantal misclassificaties min de verwachte waarde binnen regeringspartijen en binnen oppositiepartijen hoger ligt dan tussen een oppositiepartij en een regeringspartij. De verwachte waarde is afhankelijk van het aantal documenten van een partij in de training set \cite{Sahare}. Aangezien de test set uit dezelfde set als de training werd gehaald, is de verwachte waarde ook afhankelijk van het aantal documenten van een partij in de test set. Uit de voorverkenning op basis van resultaten uit deelvraag 1 en 2 bleek deze correlatie tussen het aantal \textit{false positives} van een partij en het aantal documenten behorend tot die partij.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.60\paperwidth]{Verslag/Handmatig/Correlation.png}
\caption{Het aantal \textit{false positives} ten opzichte van het aantal documenten behorend tot die partij (\textit{false negatives} en \textit{true positives}). Dit is op basis van 100 classificaties met verschillende train en test set. De Pearson correlatie is 0.77 en de p-waarde \num{5.40e-101}.}
\label{fig:correlation}
\end{figure}
Op basis van dit verband was het verwachte aantal documenten ($V_{i,j}$) van partij $i$ die foutief geclassificeerd worden als partij $j$ gedefinieerd als
\begin{equation}
\label{eq:expected}
V_{i,j}  = fn_i *  \frac{D_{j}}{D-D_{i}}
\end{equation}
waar $i\neq j$ en D het totaal aantal documenten en $D_i$ en $D_j$ het aantal documenten van respectievelijk partij $i$ en $j$. De teller van de breuk ($D_j$) is het aantal documenten die bij partij $j$ horen en de noemer het totaal aantal documenten ($D$) min het aantal documenten van partij $i$ ($D_i$). Op deze manier is $\sum_{j=0}^{n} (V_{i,j}) = fn_i$ waar $n$ het aantal partijen is minus partij $i$.\par
De error ($e_{i,j}$) is dan het verschil van  het daadwerkelijk aantal misclassificaties ($D_{i,j}$) en de verwachte waarde ($V_{i,j}$)
\begin{equation}
\label{eq:error}
e_{i,j} = D_{i,j} - V_{i,j}
\end{equation}
met opnieuw $i\neq j$ en $i$ de echte partij waar een document bijhoort en $j$ de voorspelde partij. \par
Als dit een goede benadering is van de error, dan is het te verwachten dat deze normaal verdeeld is \cite{citeulike:7531484}. Om te kijken of er een bias is, werden de distributies binnen regeringspartijen en binnen oppositiepartijen vergeleken met de distributie tussen beide groepen. Om de invloed van variantie door de willekeurige splitsing documenten voor trainen en testen te beperken, werd de classificatie 100 keer gedaan. Met behulp van normaalheidstoets is gekeken of de distributies normaal verdeeld zijn ($\alpha$ is 0.01). Als de distributies normaal verdeeld zijn, vond de statistische test plaats op basis van een eenzijdige t-toets. Als de distributies niet normaal verdeeld zijn, vond dit plaats door een Mann-whitneytoets. Het gekozen significantieniveau ($\alpha$) is 0.01. De nulhypothese is dat er geen verschil is tussen de verdelingen. De alternatieve hypothese is dan dat de distributie van binnen oppositie of regering groter is dan die tussen een regerings- en oppositiepartij. Op basis van de bevindingen van Hirst et al. was de hypothese dat de nulhypothese verworpen kan worden.\par
In het eerste experiment gebaseerd op Hirst et al. zijn de meest karakteristieke woorden per partij van een zittingsperiode vergeleken met de meest karakteristieke woorden per partij van een andere zittingsperiode, waar een kabinet uit andere partijen bestond. De verwachting is dat als de classificatie niet het gevolg is van partij-status dat de woorden bij een partij blijven en niet gekoppeld zijn aan in oppositie of regering zitten. Aansluitend bij de hypothese is dus de verwachting dat woorden wel wisselen van partij wanneer ze van partij-status gewisseld zijn.\par
In het tweede experiment gebaseerd op Hirst et al. zijn de classificaties getraind op een zittingsperiode en getest op een andere zittingsperiode, waar wederom een kabinet uit andere partijen bestond. Als de classificatie afhankelijk was van partij-status was de verwachting dat de scores van partijen die gewisseld zijn van partij-status sterker gedaald zijn dan partijen die niet van partij-status zijn veranderd. Op basis van de hypothese is dan ook de verwachting dat bij de partijen die gewisseld zijn partij-status een sterkere daling te zien is.\par
Als vergelijkingsmateriaal was voor deze experimenten een tweede dataset nodig uit een ander kabinet. Hiervoor was het wenselijk dat dit kabinet bestaat uit andere partijen dan kabinet-Rutte II. Daarnaast was het ook gewenst dat het kabinet niet te lang geleden zat, zodat onderwerpen en taalgebruik enigszins overeenkomstig zijn. Omdat kabinet-Rutte I een minderheidskabinet was met een bijzondere partij-status voor de PVV, is ervoor gekozen om de Handelingen van de Tweede Kamer tijdens het missionaire kabinet-Balkenende IV (22 februari 2007 tot 20 februari 2010) te gebruiken. Dit kabinet bestond uit CDA, PvdA en ChristenUnie.\par
De partij 50PLUS bestond nog niet gedurende kabinet-Balkenende IV, dus documenten van deze partij zijn weggelaten uit de dataset van kabinet-Rutte II. Verder heeft dezelfde verwerking van data plaatsgevonden, zoals beschreven in \ref{data}. Alleen de minimale- en maximale documentgrootte is overgenomen van de dataset van kabinet-Rutte II.\par

\begin{table}[H]
\label{aantallenBal}
\caption{Aantal documenten per partij gedurende het missionaire kabinet-Balkenende IV.}
\centering
\input{Handmatig/SpreekbeurtenBal.tex}
\end{table}

\subsubsection{DV4: Links-rechts as}
Als de classificatie afhankelijk is van positie op de links-rechts as dan is het te verwachten dat, net als bij deelvraag 3, de misclassificaties minus de verwachte waarde groter zijn als twee partijen dichterbij elkaar staan op de links-rechts as.  Daarvoor werd wederom formule \ref{eq:expected} gebruikt als verwachte waarde en formule \ref{eq:error} als error. De hypothese is dat de classificatie deels afhankelijk is van positie op de links-recht as.\par
Er zijn verschillende methoden om partijen in te delen op een links-rechts as. Er is hier gekozen voor de indeling van het Manifesto Project \cite{Volkens:2017}. Het Manifesto Project geeft scores op een heel aantal politieke posities, waaronder de links-rechts as, op basis van het verkiezingsprogramma van dat jaar. Voor de dataset van kabinet-Rutte II is gebruikt gemaakt van de scores op basis van de verkiezingsprogramma's voor de verkiezingen van 2012. \par
\begin{table}[H]
\centering
\caption{Scores op de links-rechts as per partij van het Manifesto Project voor de verkiezingsprogramma's van 2012.}
\label{my-label}
\centering
\begin{tabular}{lc}
\toprule
Partij  & Score van Manifesto Project \\
\midrule
SP           & -20.926 \\ 
GroenLinks   & -9.584 \\ 
PvdA         & -6.558 \\ 
PvdD         & -6.465 \\ 
50PLUS       & -6.311\\ 
D66          & -0.778\\ 
ChristenUnie & 10.203\\ 
PVV          & 15.642\\ 
CDA          & 17.701\\
VVD          & 22.629\\ 
SGP          & 26.6\\ 
\bottomrule
\end{tabular}
\end{table}
Er wordt vervolgens gekeken door middel van een Pearson correlatie toets of er een correlatie is tussen de error van twee partijen en de afstand op de links-rechts as van die partij. Het significantieniveau ($\alpha$) hiervoor is opnieuw 0.01. De nulhypothese is dat er geen negatieve correlatie is tussen de error en de afstand op de links-rechts as. De alternatieve hypothese is dat er wel een negatieve correlatie is tussen de error en de afstand op de links-rechts as.\par
Als uit deelvraag 3 blijkt dat partij-status invloed heeft op de error, zal bovenstaande methode ook uitgevoerd worden voor de aparte combinaties; binnen oppositie en tussen regeringspartij en oppositiepartij. Binnen regering is dit niet mogelijk aangezien er maar één afstand is, die tussen PvdA en VVD.\par
De voorspelling op basis van de hypothese is dat de nulhypothese verworpen kan worden.\par

\subsubsection{DV5: Woordgebruik van sprekers}
De vorige classificaties trainden op documenten en werden getest op andere documenten, maar wel van dezelfde sprekers als uit de training set. Naast de ideologie kan de classificatie daarom ook getraind zijn op het taalgebruik van sprekers. Als een Kamerlid bijvoorbeeld een woord regelmatig in speeches gebruikt, maar niet werd gebruikt door zijn partijgenoten, werd dit wel gezien als een belangrijk woord voor de classificatie naar partij-affiliatie. Hirst et al. \cite{Hirst_textto} plaatsten al een soortgelijke kanttekening bij de resultaten van Diermeier et al. \cite{diermeier_godbout_yu_kaufmann_2012}. De hypothese is dat de classificatie afhankelijk is van woordgebruik van sprekers\par
Om te kijken of dit effect er is, werd er opnieuw een classificatie gedaan met de classificatiemethode uit deelvraag 1 zonder achternamen van Kamerleden en partijnamen. Ditmaal werden alleen niet de individuele documenten verdeeld over de training en test set, maar werden de Kamerleden, met bijbehorende documenten, verdeeld over de training en test set. Als taalgebruik van een spreker in de training set voorheen invloed had op de classificatie, zou dat nu geen effect meer moeten hebben omdat er geen documenten van die spreker meer voorkomen in de test set. De verwachting is daarom ook dat deze classificatie lagere scores vindt dan die van deelvraag 2.\par

% hypothese

% https://www.google.nl/search?q=grafiek+2012+kieskompas&safe=off&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjigpaDoIXbAhUSJlAKHUBzBQ4Q_AUoAXoECAAQAw&biw=1920&bih=943#imgrc=Dekv0sSQBTnikM: