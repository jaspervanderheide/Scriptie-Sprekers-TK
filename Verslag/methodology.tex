\section{Methodologie}
\label{sec:meth}


\subsection{De data}
De data die gebruikt worden, zijn de Handelingen van de Tweede Kamer gedurende het missionaire kabinet-Rutte II (5 november 2012 tot 22 maart 2017). Deze data is in xml-formaat van de website officielebekendmakingen.nl gehaald, samen met corresponderende metadata xml-bestanden. De bestanden van de Handelingen bevatten voornamelijk informatie over spreekbeurten tijdens een debat, waaronder naam van een spreker, partij-affiliatie, inhoud van de spreekbeurt en het soort spreekbeurt. Deze gegevens zijn samengevoegd tot een tabel en opgeslagen als csv-bestand.\par

Deze dataset bestaat uit een aantal soorten spreekbeurten, zoals speeches, interrupties en antwoorden. Daarnaast ook door verschillende soorten sprekers, zoals de voorzitter, Tweede Kamerleden, leden van het kabinet en gastsprekers. Uit deze dataset is gekozen voor de eerste spreekbeurt nadat een spreker achter het spreekgestoelte is gaan staan, aangezien deze vaak langer zijn dan de andere spreekbeurten en naar verwachting meer zeggen over ideologie. In de oorspronkelijke xml-bestanden hadden deze spreekbeurten het attribuut \textit{nieuw="ja"}.  Daarnaast is alleen gekozen voor sprekers waarvan er een partij-affiliatie vermeld staat, dit is niet het geval voor leden van het kabinet, de voorzitter en gastsprekers  (met uitzondering van Nederlandse leden van het Europees Parlement).\par

Deze dataset bevat daarna naast de verkozen partijen van de 2012 Tweede Kamerverkiezingen, ook afsplitsingen van die partijen (tien in totaal) en bezoeken van vertegenwoordigingen van die partijen uit het Europees Parlement (tien in totaal). Omdat van beide categori\"{e}n relatief weinig data is en er overlap zit met hun oorspronkelijke partij, zijn deze er uit gehaald.
\begin{table}[H]
\caption{Aantal spreekbeurten per partij gedurende het missionaire kabinet-Rutte II.}
\centering
\input{Tables/Spreekbeurten}
\end{table}




\subsection{Methoden}


\subsubsection{Deelvraag 1}

Om deze deelvraag te beantwoorden zullen een aantal classificatiemethoden vergeleken worden. Aangezien het onmogelijk om alle classificatiemethoden te vergeleken, beperkt dit onderzoek zich tot classificatiemethoden die goede resultaten hebben opgeleverd in andere onderzoeken, genoemd in \ref{sec:Deelvraag1}. Daarnaast is omwille van de tijd ervoor gekozen om alleen gebruik te maken van methoden waarvan reeds implementaties beschikbaar waren in Python. Hieronder worden de verschillende onderdelen besproken.

\paragraph{Pre-processing}
Voor pre-processing is gebruik gemaakt van tokenisation, lowercasing en stemming. Voor tokenisation is de reguliere expressie $\\w+$ gebruikt, die daarmee alleen de letters van het alfabet overhoudt. Deze woorden zijn vervolgens allemaal omgezet in kleine letters. Vervolgens is er gevarieerd tussen wel of geen gebruik maken van stemming. In het geval van stemming is gebruik gemaakt van de Snowball Stemmer via de Python NLTK module.

\paragraph{Bag-of-words model}
Bag-of-words model is de meest gebruikte representatie van data in vergelijkbare onderzoeken. Bij het bag-of-words model wordt elk document gerepresenteerd door een vector, waarbij elke kolom een woord voorstelt met een bijbehorende waarde. Voornaamste beperking van dit model is dat het geen rekening houdt met de volgorde van woorden, wat een groot effect kan hebben op de betekenis van een document.\par
Voor dit onderzoek zijn de volgende wegingen voor woorden getest: \textit{boolean} (wel of niet aanwezig), \textit{tf} (woordfrequentie), \textit{tf-norm} (woordfrequentie genormaliseerd door documentlengte) en \textit{tf-idf}
Daarnaast wordt in dit onderzoek geëxperimenteerd met een minimale of maximale woord- of documentfrequentie. Ook is zowel gekeken naar alleen unigrams als features, alsook het toevoegen van bi- en trigrams.\par

\paragraph{Support Vector Machines}
Een veel gebruikte techniek is Support Vector Machine (SVM). In meeste onderzoeken wordt niet gespecificeerd welke vorm van SVM gebruikt wordt. Om deze reden zal in dit onderzoek uitgebreid gekeken worden naar welke vorm het beste resultaat geeft. Hierbij wordt gebruik gemaakt van de functie SVC van sklearn en de variant met \textit{stochastic gradient descent learning} SGDClassifier. In beide gevallen wordt gevarieerd met de regularisatie.
In het geval van de SVC functie wordt ook gevarieerd met de parameter C. \par
\paragraph{Logistische Regressie}
\paragraph{Naive Bayes}
\paragraph{Beoordelen van kwaliteit}
De meest gebruikte methoden om kwaliteit van politieke tekstclassificatie te beoordelen zijn Accuracy en F1-score, die opgebouwd is uit recall en precision. \par
\begin{table}[H]
\centering
\caption{Voorbeeld confusion matrix.}
\begin{tabular}{|l|l|l|}
\diagbox{Echte waarde}{Voorspelde waarde} & Positief & Negatief \\ \hline
Positief & tp & fn \\ \hline
Negatief & fp & tn \\ \hline
\end{tabular}
\end{table}
\begin{equation}
    Precision = \frac{tp}{tp + fp}\\
\end{equation}
\begin{equation}
    Recall = \frac{tp}{tp + tn}
\end{equation}
\begin{equation}
    Accuracy = \frac{tp + tn}{tp + tn + fp + fn}
\end{equation}

% https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-text-classification-1.html
\bigskip
Voor de classificatiemethoden wordt waar mogelijk gebruik gemaakt van functies van de Python module scikit-learn\cite{scikit-learn}, aangevuld met zelf geschreven code als dit niet reeds beschikbaar is. Bij al deze classificatiemethoden wordt gevarieerd met meerdere parameters door middel van een gridsearch. Hierbij wordt gebruikt gemaakt van 5-fold cross-validation. Hierbij wordt de data gespleten in vijf delen, waarvan steeds één deel als test wordt gebruikt.

\subsubsection{Deelvraag 2}
In het onderzoek van Diermeier et al. worden alle eigennamen weggelaten zodat, volgens hen, namen van personen en partijen niet de classificatie domineren. Aangezien hier bij deelvraag 1 niet voor is gekozen, wordt bij deze deelvraag gekeken hoe groot het effect hiervan is, specifiek gericht op partijnamen en namen van kamerleden. Voor deze deelvraag wordt wederom een classificatie gedaan met de classificatiemethode die resulteerde uit deelvraag 1. In deze classificatie worden alle partijnamen vervangen door de tag PARTIJNAAM en alle namen van Kamerleden vervangen door de KAMERLIDNAAM. Deze resultaten worden vervolgens vergeleken met de resultaten uit deelvraag 1. 

\subsubsection{Deelvraag 3}

Om deze deelvraag te beantwoorden zullen de twee experimenten die Graeme Hirst et al. uitvoerden voor dezelfde vraag gereproduceerd worden op de dataset van de Tweede Kamer. Bij deze deelvraag zal de beste classifier uit deelvraag 1 gebruikt worden. \par
Als vergelijkingsmateriaal is voor deze experiment een tweede dataset nodig uit een ander kabinet. Hiervoor is het wenselijk dat dit kabinet bestaat uit andere partijen dan kabinet-Rutte II. Er moet voor het derde experiment variatie zijn in de Kamerleden tussen de twee kabinetten, maar ook voldoende Kamerleden die in beide perioden in de kamer zaten. Daarnaast is het ook wenselijk als het niet te ver terug is, zodat onderwerpen en taalgebruik enigszins overeenkomstig zijn. Omdat kabinet-Rutte I een minderheidskabinet was met een bijzondere partij-status voor de PVV, is ervoor gekozen om de Tweede Kamer tijdens het missionaire kabinet-Balkenende IV (22 februari 2007 tot 20 februari 2010) te gebruiken.\par
In het eerste experiment zullen de tien meest karakteristieke woorden per partij van het ene parlement vergeleken worden met de tien meest karakteristieke woorden per partij van het andere parlement. Als de classificatie op basis van ideologie is in plaats van partij-status, is het te verwachten dat de woorden bij een partij blijven en niet gekoppeld zijn aan in oppositie of regering zitten. \par
In het tweede experiment worden classifiers getraind op het ene parlement en getest op het andere parlement. Als de classificatie op basis van ideologie is in plaats van partij-status, is de verwachting dat er nog steeds aanzienlijke voorspellingen gedaan worden, aangezien de ideologie naar verwachting redelijk stabiel is binnen tien jaar (hoewel woordgebruik varieert). Als de scores aanzienlijk lager zijn, kan dit het gevolg zijn van het veranderen van partij-status van partijen.\par

\subsubsection{Deelvraag 4}
Voor deze deelvraag vergelijken we de resultaten van de eerdere classificatie per partij met een binaire classificatie op basis van rechts en links. Hiervoor wordt wederom de dataset van kabinet-Rutte 2 gebruikt, met het model wat resulteerde uit deelvraag 1. \par
Voor deze vraag moet vastgesteld worden welke partijen links en rechts zijn. Omdat dit lastig te bepalen is en er meerdere indelingen zijn, wordt hier gebruik gemaakt van twee verschillende indelingen. De indeling op basis van het Kieskompas van Andre Krouwel voor de Kamerverkiezing 2012 en de indeling volgens het Manifesto Project gebaseerd op verkiezingsprogramma's voor de Kamerverkiezing van 2012\cite{Volkens:2017}. In beide gevallen is de nullijn van het politieke spectrum gebruikt om te bepalen of een partij links of rechts is.\par

\begin{table}[H]
\centering
\caption{Rechts (R) of link (L) indeling per partij op basis van het Kieskompas en het Manifesto Project.}
\label{my-label}
\centering
\begin{tabular}{lll}
\hline
Partij  & Kieskompas & Manifesto Project \\ \hline
SP           & L & L\\ 
PvdA         & L & L\\ 
GroenLinks   & L & L\\ 
PvdD         & L & L\\ 
50PLUS       & L & L\\ 
D66          & R & L\\ 
PVV          & - & R\\ 
ChristenUnie & R & R\\ 
SGP          & R & R\\ 
VVD          & R & R\\ 
CDA          & R & R\\
\end{tabular}
\end{table}

% hypothese

% https://www.google.nl/search?q=grafiek+2012+kieskompas&safe=off&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjigpaDoIXbAhUSJlAKHUBzBQ4Q_AUoAXoECAAQAw&biw=1920&bih=943#imgrc=Dekv0sSQBTnikM:
% https://www.parlement.com/id/vh8lnhrp8wsy/links_en_rechts