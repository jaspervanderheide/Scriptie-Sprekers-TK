\section{Gerelateerd werk}
\label{sec:rel}

Toespraken in parlementen worden veel gebruikt in tekstclassificatie, omdat deze veel nette tekst bevatten en vaak gelabeld zijn. Labels zijn bijvoorbeeld naam en partij van de spreker, maar ook daar uit afleidbare labels zoals geslacht, leeftijd en partij-status (oppositie of regering).\par
In dit hoofdstuk zullen verschillende onderzoeken behandeld worden die tekstclassificatie hebben toegepast op parlementaire teksten. Eerst zullen de onderzoeken algemeen besproken worden. Vervolgens is uitgebreider gekeken worden de effecten van verschillende classificatiemethoden. In de latere secties worden de aspecten besproken die in vergelijkbare onderzoeken genoemd worden als van invloed op de classifcatie.

\subsection{Tekstclassificatie van parlementaire teksten}

Diermeier et al. deden onderzoek naar het classificeren op basis van ideologische positie in de Amerikaanse Senaat \cite{diermeier_godbout_yu_kaufmann_2012}. Ze trainden hun classificatie op de speeches van de 25 meest liberale en de 25 meest conservatieve senatoren van het 101e tot en met het 107e Congres en testten op dezelfde categorieën van het 108e Congres. Een document was in dit onderzoek de verzameling van alle speeches van een senator in een Congres. Deze classificatie resulteerde uiteindelijk in een nauwkeurigheid van 94\% (baseline van 50\%). Van de 50 senatoren in de test set, kwamen er 44 al voor in de training set, doordat de training op voorgaande Congressen was.\par
Later in het onderzoek vergeleken ze ook de 25 gematigd conservatieve  en de 25 gematigd liberale senatoren van dezelfde Congressen. Het resultaat hiervan was 52\% (baseline van 50\%), dus nauwelijks beter dan de baseline. Als verklaring voor dit verschil ten opzichte van de uitersten zeggen ze dat gematigden een minder duidelijke ideologie hebben.\par
Yu et al. \cite{doi:10.1080/19331680802149608} richtten zich vervolgens op zowel het Amerikaanse Huis van Afgevaardigden als de Senaat in 2005. Een document was in dit onderzoek de verzameling van alle speeches van een congreslid en het label de partij. Voor het Huis van Afgevaardigden vonden ze een nauwkeurigheid van 80.1\% (baseline van 51.5\%) en voor de Senaat 86.0 \% (baseline van 55.0\%). Ze testten hun classificaties ook op de andere kamer. Van Huis van Afgevaardigden naar Senaat leverde dit een nauwkeurigheid op van 88.0\% (baseline van 55.0\%) en andersom 67.6\% (baseline van 51.5\%). Hun verklaring voor dit verschil was dat het Huis van Afgevaardigden sterker verdeeld is langs partijlijnen.\par
Vervolgens herhaalden ze de classificaties op het Huis van Afgevaardigden uit 2015, maar testten ditmaal op de Senaat elk jaar tussen 1989 en 2006 afzonderlijk. Hierin was een stijging in nauwkeurigheid van 60.0\% (baseline van 55.0\%) in 1989 naar 87.0\% (baseline van 55.0\%) in 2006 te zien, maar met twee duidelijke dalen. Ze presenteren twee mogelijke verklaringen voor de trend; het veranderen van de onderwerpen en het sterker verdeeld worden van het Congres. \par
Als een vervolg op deze onderzoeken deden Hirst et al. een vergelijkbaar onderzoek naar het Canadese Parlement \cite{Hirst_textto}. Hierbij werd zowel gekeken naar de Engelse als Franse teksten. Een document werd hier gezien als de samenvoeging van alle spreekbeurten van een spreker. Afhankelijk van taal en dataset vonden zij in dit onderzoek nauwkeurigheden van 83.2\%  en hoger (baseline van 65.5\%).\par
Het onderzoek bevat ook een classificatie van het Europees Parlement. Hierbij werden alle teksten van een parlementslid bij elkaar gevoegd en opgedeeld in documenten van gelijke grootte. Voor documentgrootte van 267 woorden werd een nauwkeurigheid van 44.0\%  gevonden oplopend tot 61.8\% (baseline van 38-39\%) voor documentgrootte van 6666.\par

Bhand et al. \cite{bhand} richtten zich op het classificeren van leden van het Amerikaanse Congres in 2005, op basis van partij-affiliatie (Republikeins of Democratisch). Een document hierbij was in tegenstelling tot eerdergenoemde onderzoeken een speech. Zij vonden hiervoor uiteindelijk een $F_1$ score van 0.68 (baseline niet vermeld).\par

Ferreira \cite{Ferreira2016UsingTT} probeerde interventies van politici te classificeren op basis van geslacht, leeftijdsgroep, partij-affiliatie en oriëntatie in het Portugese parlement. In het geval van classificatie op basis van partij-affiliatie bereikte men een $F_1$ score van 0.90 (baseline niet vermeld, zes partijen).\par

Høyland et al. \cite{W14-2516} trainden een classificatie voor partij-affiliatie op basis van teksten van het vijfde Europese Parlement (1999-2004) en testten vervolgens op het zesde Europese Parlement (2004-2009). Alle teksten van een spreker waren samengevoegd tot één document. 40\% van de sprekers in de test set zaten ook in de training set. Hier werd een macro $F_1$ score van 0.464 (baseline van 0.097) en nauwkeurigheid van 0.551 (baseline van 0.410) verkregen. De baseline is in dit onderzoek op basis van het altijd classificeren als grootste partij, terwijl voor $F_1$ score de baseline hoger ligt als hiervoor gekozen wordt voor gokken gewogen bij grootte van een klasse. \par

\subsection{Classificatiemethoden}
\label{sec:Deelvraag1}
Diermeier et al. \cite{diermeier_godbout_yu_kaufmann_2012} gebruikten Support Vector Machines. Verder maakten ze gebruik van \textit{tf-idf} met een minimale woordfrequentie van 50 en een minimale documentfrequentie van 10 en \textit{Part-Of-Speech tagging}.\par

Yu et al. \cite{doi:10.1080/19331680802149608} maakten gebruik van Support Vector Machines en Naive Bayes, waarvan de varianten multinomial en Bernoulli. De features waren unigrams, met minimale woordfrequentie van drie en de top 50 meest voorkomende woorden weggelaten. Voor de wegingen van de features bij Support Vector Machines werd geëxperimenteerd met \textit{boolean}, \textit{tf-norm} en \textit{tf-idf}. De beste classificatiemethode was afhankelijk van de dataset. Voor het Huis van Afgevaardigden was het Support Vector Machines met als weging \textit{tf-idf} en voor de Senaat Bernouilli Naive Bayes.

Hirst et al. \cite{Hirst_textto} maakten  gebruik van Support Vector Machines. Ze experimenteerden met verschillende vormen van pre-processing, inclusief stemmen en het verwijderen van woorden op basis van te hoge of te lage frequentie. Deze variaties maakten in hun onderzoek geen grote verschillen en uiteindelijk is gekozen voor het niet stemmen, het weglaten van woorden die in minder dan vijf documenten voorkomen en resultaten van zowel met als zonder de top 500 meest frequente woorden. Daarnaast werd geëxperimenteerd met vier wegingen voor woorden: \textit{boolean}, \textit{tf}, \textit{tf-norm} en \textit{tf-idf}, waarvan \textit{tf-idf} het beste resultaat opleverde. \par

Bhand et al. \cite{bhand} gebruikten verschillende n-grams, inclusief verschillende manieren van \textit{smoothing}. Ze testten als weging voor features zowel \textit{boolean} als \textit{tf}, waarbij ze vonden dat \textit{boolean} betere resultaten opleverden. Voor classificatiemodel experimenteerden ze met SVM en Naive Bayes. Voor het selecteren van \textit{features} experimenteerden ze met een minimale frequentie en selectie van woorden op basis van hoogste \textit{mutual information}. Uiteindelijk was het beste model bij hen een SVM met uni- en bigrams en geselecteerd op basis van \textit{mutual information}.\par

Ferreira maakten gebruik van twee classificatiemethoden: Logistische regressie en \textit{margin-infused relaxed algorithm} (MIRA) \cite{Ferreira2016UsingTT}. Logistische regressie werd aangevuld met \textit{group Lasso} regularisatie, wat het beste resultaat opleverde. Voor wegingen van woorden werd geëxperimenteerd met \textit{tf}, \textit{tf-idf}, \textit{$\Delta$-tf-idf} en \textit{$\Delta$-BM-25}. Daarnaast wordt er gebruik gemaakt van woordclustering, \textit{Concise Semantic Analysis} en stylometrische eigenschappen. Op \textit{Part-Of-Speech tagging} na hadden stylometrische eigenschappen een duidelijke negatieve invloed op de classificatie.\par
Høyland et al. maakten gebruik van Support Vector Machine \cite{W14-2516}. Als beste waarde voor de regularisatieterm, de C-parameter, vonden zij 0.8. Daarnaast gebruikten zij \textit{dependency disambiguated
stems}, wat een $F_1$ score van twee procent hoger opleverde dan gebruik van normale stemming.\par

\subsection{Invloed van partijnamen of sprekersnamen}
Diermeier et al. \cite{diermeier_godbout_yu_kaufmann_2012} lieten de namen van de sprekers en verwijzingen naar staten die de senatoren representeren weg, omdat deze volgens hen de classificatie te makkelijk zouden maken. Hirst et al. \cite{Hirst_textto} vonden inderdaad dat partijnamen - en het weglaten daarvan - bij het Europees Parlement een grote invloed hebben op de classificatie. Bij het Europees Parlement was te zien dat een spreker de eigennaam gebruikte, terwijl in het Canadese parlement vooral te zien was dat de naam van de andere partij gebruikt wordt door een spreker.

\subsection{Invloed van oppositie of regering}
Hirst et al. \cite{Hirst_textto} vonden in hun onderzoek dat de classificatie van spreker in het Canadese parlement op basis van partij-affiliatie meer zegt over de status van de partij (regering of oppositie). Zo vergeleken zij de top tien karakteristieke woorden van de liberalen en conservatieven in het 36e parlement (liberalen in de regering) en het 39e parlement (conservatieven in de regering. Hier vonden zij dat vier van de tien woorden van de liberalen (regering) in het 36e parlement bij het 39e parlement bij de conservatieven (regering) te vinden waren. Andersom gebeurde hetzelfde met één van de tien woorden van de conservatieven (oppositie) in het 36e parlement naar liberalen (oppositie) in het 39e parlement.\par
In hetzelfde onderzoek trainden ze ook hun classificaties op het ene parlement en testten deze op het andere parlement. Hierbij vonden zij in beide gevallen een nauwkeurigheid ver onder de baseline. \par
Deze resultaten leidden de onderzoekers tot de conclusie dat de classificatie voornamelijk het gevolg is van de status van de partij en minder van ideologie.\par

\subsection{Invloed van de links-rechts as}
Hirst et al. \cite{Hirst_textto} onderzochten of de positie op links-rechts as van invloed was op de classificatie van het Europees Parlement. Hiervoor deden zij zowel een binaire classificatie (links of rechts) als een classificatie met meerdere klassen, waarbij elke partij een klasse is. Het verschil in nauwkeurigheden, gecompenseerd voor het verschil in baseline, suggereerde volgens hen dat classificatie op basis van partij niet veel moeilijker is dan binaire classificatie. Wel zagen zij bij de classificatie op basis van partij dat de misclassificaties hoger waren tussen partijen die ideologisch dicht bij elkaar lagen. Hiervoor werd niet gecompenseerd voor het feit dat de verwachte waarde afhankelijk kan zijn van de grootte van de klasse, wat een vertekend beeld kan geven. Ook zagen zij in de meest karakteristieke woorden een weerspiegeling van ideologie.