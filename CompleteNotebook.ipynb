{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sn\n",
    "import xlrd\n",
    "import operator\n",
    "import math\n",
    "import openpyxl\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "from decimal import Decimal\n",
    "from IPython.display import display, HTML\n",
    "from ast import literal_eval\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer(\"dutch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv(\"HandelingenRutte2.csv\", index_col=0)\n",
    "df = df.loc[df['speech category'] == 'Main Speech']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>speech category</th>\n",
       "      <th>date</th>\n",
       "      <th>tags</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>normal_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286900</th>\n",
       "      <td>Wilders</td>\n",
       "      <td>PVV</td>\n",
       "      <td>\\r\\n           \\r\\n             Mevrouw de voo...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>Main Speech</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "      <td>mevrouw de voorzitter dit kabinet heeft ons mo...</td>\n",
       "      <td>mevrouw de voorzitter dit kabinet heeft ons mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286901</th>\n",
       "      <td>Roemer</td>\n",
       "      <td>SP</td>\n",
       "      <td>\\r\\n           \\r\\n             Voorzitter. Vo...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>Main Speech</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "      <td>voorzitter vorig wek plaatst werkgever werknem...</td>\n",
       "      <td>voorzitter vorige week plaatsten werkgevers we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286902</th>\n",
       "      <td>Pechtold</td>\n",
       "      <td>D66</td>\n",
       "      <td>\\r\\n           \\r\\n             Voorzitter. Tw...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>Main Speech</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "      <td>voorzitter twee maand geled kreg dit kabinet v...</td>\n",
       "      <td>voorzitter twee maanden geleden kreeg dit kabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286903</th>\n",
       "      <td>Van Haersma Buma</td>\n",
       "      <td>CDA</td>\n",
       "      <td>\\r\\n           \\r\\n             Voorzitter. Al...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>Main Speech</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "      <td>voorzitter allen al in de eerst drie maand van...</td>\n",
       "      <td>voorzitter alleen al in de eerste drie maanden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286912</th>\n",
       "      <td>Thieme</td>\n",
       "      <td>PvdD</td>\n",
       "      <td>\\r\\n           \\r\\n             Voorzitter. We...</td>\n",
       "      <td>h-tk-20122013-100-3.xml</td>\n",
       "      <td>Main Speech</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>['Bestuur | Parlement', 'Financiën | Begroting']</td>\n",
       "      <td>voorzitter we zijn eruit eerst ontdekt de mini...</td>\n",
       "      <td>voorzitter we zijn eruit eerst ontdekte de min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 surname party  \\\n",
       "286900           Wilders   PVV   \n",
       "286901            Roemer    SP   \n",
       "286902          Pechtold   D66   \n",
       "286903  Van Haersma Buma   CDA   \n",
       "286912            Thieme  PvdD   \n",
       "\n",
       "                                                     text  \\\n",
       "286900  \\r\\n           \\r\\n             Mevrouw de voo...   \n",
       "286901  \\r\\n           \\r\\n             Voorzitter. Vo...   \n",
       "286902  \\r\\n           \\r\\n             Voorzitter. Tw...   \n",
       "286903  \\r\\n           \\r\\n             Voorzitter. Al...   \n",
       "286912  \\r\\n           \\r\\n             Voorzitter. We...   \n",
       "\n",
       "                           file speech category        date  \\\n",
       "286900  h-tk-20122013-100-3.xml     Main Speech  2013-06-26   \n",
       "286901  h-tk-20122013-100-3.xml     Main Speech  2013-06-26   \n",
       "286902  h-tk-20122013-100-3.xml     Main Speech  2013-06-26   \n",
       "286903  h-tk-20122013-100-3.xml     Main Speech  2013-06-26   \n",
       "286912  h-tk-20122013-100-3.xml     Main Speech  2013-06-26   \n",
       "\n",
       "                                                    tags  \\\n",
       "286900  ['Bestuur | Parlement', 'Financiën | Begroting']   \n",
       "286901  ['Bestuur | Parlement', 'Financiën | Begroting']   \n",
       "286902  ['Bestuur | Parlement', 'Financiën | Begroting']   \n",
       "286903  ['Bestuur | Parlement', 'Financiën | Begroting']   \n",
       "286912  ['Bestuur | Parlement', 'Financiën | Begroting']   \n",
       "\n",
       "                                             stemmed_text  \\\n",
       "286900  mevrouw de voorzitter dit kabinet heeft ons mo...   \n",
       "286901  voorzitter vorig wek plaatst werkgever werknem...   \n",
       "286902  voorzitter twee maand geled kreg dit kabinet v...   \n",
       "286903  voorzitter allen al in de eerst drie maand van...   \n",
       "286912  voorzitter we zijn eruit eerst ontdekt de mini...   \n",
       "\n",
       "                                              normal_text  \n",
       "286900  mevrouw de voorzitter dit kabinet heeft ons mo...  \n",
       "286901  voorzitter vorige week plaatsten werkgevers we...  \n",
       "286902  voorzitter twee maanden geleden kreeg dit kabi...  \n",
       "286903  voorzitter alleen al in de eerste drie maanden...  \n",
       "286912  voorzitter we zijn eruit eerst ontdekte de min...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemmed_text'] = df.text.apply(lambda x: ' '.join([stemmer.stem(t) for t in tokenizer.tokenize(x)]))\n",
    "df['normal_text'] = df.text.apply(lambda x: ' '.join([t.lower() for t in tokenizer.tokenize(x)]))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50PLUS           413\n",
       "CDA             2216\n",
       "ChristenUnie    1223\n",
       "D66             2211\n",
       "GroenLinks      1193\n",
       "PVV             1880\n",
       "PvdA            2269\n",
       "PvdD             480\n",
       "SGP              770\n",
       "SP              2573\n",
       "VVD             2157\n",
       "Name: party, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a dataframe with counts of dataset per party\n",
    "countdf = df.party.value_counts().sort_index()\n",
    "with open(\"Verslag/Tables/Spreekbeurten.tex\", \"w\") as f:\n",
    "    f.write(countdf.to_latex(header=False))\n",
    "countdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tekst = chain.from_iterable([list(set(doc)) for doc in df.list_text])\n",
    "# count = Counter(tekst)\n",
    "# samples = list(count.values())\n",
    "# t = Counter(samples)\n",
    "# t = sorted(t.items())\n",
    "# x, y = zip(*t)\n",
    "# plt.loglog(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = Counter([len(doc) for doc in df.list_text])\n",
    "# t = sorted(t.items())\n",
    "# x, y = zip(*t)\n",
    "# plt.plot(x, y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelsdownload(only_doen=False):\n",
    "    models_df = pd.read_excel('Models.xlsx', index_col=0)\n",
    "    if only_doen:\n",
    "        models_df = models_df.loc[models_df.DOEN == True]\n",
    "    models_dict = {}\n",
    "    for x,y in zip(models_df.Classifier, models_df.PIPELINE):\n",
    "        exec(compile(\"a=\"+y,'','exec'), globals())\n",
    "        models_dict[x] = Pipeline(a)\n",
    "    return models_df, models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df, models_dict = modelsdownload(True)\n",
    "\n",
    "# Creates a dict with parameters per classifier   \n",
    "params_dict = {}\n",
    "for clf in set(models_df.Classifier):\n",
    "    params_df = models_df.loc[models_df.Classifier == clf]\n",
    "    params_df = params_df.loc[params_df.DOEN == True]\n",
    "    params_df = params_df.dropna(axis=1, how='all')\n",
    "    params_df = params_df.drop([col for col in params_df.columns if \"__\" not in col], axis=1)\n",
    "    temp_dict = {}\n",
    "    for x, y in params_df.to_dict(orient='list').items():\n",
    "        a = literal_eval(y[0])\n",
    "        temp_dict[x] = a   \n",
    "    params_dict[clf] = temp_dict\n",
    "    \n",
    "text_dict = {x:y for x, y in zip(models_df.Classifier, models_df.RAW)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1_weighted', 'precision_weighted','recall_weighted']\n",
    "for name, pipe in models_dict.items():\n",
    "    \n",
    "    if text_dict[name]:\n",
    "         text = list(df.normal_text)\n",
    "    else:\n",
    "        text = list(df.stemmed_text)\n",
    "        \n",
    "    gs = GridSearchCV(pipe, params_dict[name], cv=-1, scoring=scoring, refit = False, return_train_score = False, n_jobs=5)\n",
    "    gs.fit(text, df.party)\n",
    "    rows = pd.DataFrame(gs.cv_results_)\n",
    "    # https://stackoverflow.com/questions/38231591/splitting-dictionary-list-inside-a-pandas-column-into-separate-columns\n",
    "    rows = pd.concat([rows.drop(['params'], axis=1), rows['params'].apply(pd.Series)], axis=1)\n",
    "    rows[\"name\"] = name\n",
    "    pd.concat([rows, pd.read_csv('Scores.csv', index_col=0)], ignore_index=True).sort_values(['mean_test_f1_weighted'], ascending=False).to_csv('Scores.csv')\n",
    "    df4 = pd.read_excel('Models.xlsx', index_col=0)\n",
    "    df4.loc[df4.Classifier == name, \"DOEN\"] = False\n",
    "    df4.to_excel('Models.xlsx')\n",
    "    print(\"Voltooid: %s\" %name)\n",
    "    \n",
    "# https://stackoverflow.com/questions/46735847/save-best-params-in-gridsearch-in-a-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/36271413/pandas-merge-nearly-duplicate-rows-based-on-column-value?rq=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 <class 'float'>\n",
      "5 <class 'int'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the classifier and parameters with highest score\n",
    "scores = pd.read_csv('Scores.csv', index_col=0).head(1)\n",
    "scores = scores.dropna(axis=1).reset_index(drop=True)\n",
    "scores.vect__ngram_range[0] = literal_eval(scores.vect__ngram_range[0])\n",
    "models_df, models_dict = modelsdownload(False)\n",
    "text_dict = {x:y for x, y in zip(models_df.Classifier, models_df.RAW)}\n",
    "pipe = models_dict[scores.name[0]]\n",
    "params = scores.drop([col for col in scores.columns if \"__\" not in col or \"param\" in col], axis=1).to_dict(orient='records')[0]\n",
    "params['vect__min_df'] = int(params['vect__min_df'])\n",
    "pipe.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13908\n"
     ]
    }
   ],
   "source": [
    "df_train = df.sample(frac=0.8)\n",
    "df_test_index = list(set(df.index.tolist()) - set(df_train.index.tolist()))\n",
    "df_test = df[df.index.isin(df_test_index)]\n",
    "print(len(df_train.stemmed_text))\n",
    "if text_dict[scores.name[0]]:\n",
    "    pipe.fit(list(df_train.normal_text), list(df_train.party))\n",
    "    predicted = pipe.predict(df_test.normal_text)\n",
    "else:\n",
    "    pipe.fit(df_train.stemmed_text, df_train.party)\n",
    "    predicted = pipe.predict(df_test.stemmed_text)\n",
    "print(classification_report(df_test.party, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pipe.named_steps['vect'].vocabulary_\n",
    "inv_vocab = {v: k for k, v in woord.items()}\n",
    "coefs = pipe.named_steps['SGD'].coef_\n",
    "top_words = []\n",
    "for i in range(coefs.shape[0]):\n",
    "    temp_list = []\n",
    "    for t in coefs[i].argsort()[-10:][::-1]:\n",
    "        temp_list.append(inv_vocab[t])\n",
    "    top_words.append(temp_list)\n",
    "top_words = pd.DataFrame(top_words).T\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Echte klasse')\n",
    "    plt.xlabel('Voorspelde klasse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "cnf_matrix = confusion_matrix(df_test.party, predicted)\n",
    "plot_confusion_matrix(cnf_matrix, \\\n",
    "                      classes=sorted(list(df.party.unique())), \\\n",
    "                      title='Confusion matrix best estimator')\n",
    "plt.savefig(\"Verslag/confusionmatrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull\n",
    "!git add CompleteNotebook.ipynb\n",
    "!git add Scraper.ipynb\n",
    "!git add Scores.csv\n",
    "!git add Scriptie_Sprekers_TK.pdf\n",
    "!git add Verslag/Tables/Spreekbeurten.tex\n",
    "#!git add Verslag/Tables/MItable.tex\n",
    "#!git add Verslag/Tables/MItable2.tex\n",
    "!git add Models.xlsx\n",
    "!git add Verslag/confusionmatrix.png\n",
    "!git commit -m Update\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
