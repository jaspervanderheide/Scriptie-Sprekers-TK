{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\m6800\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "# Sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import seaborn as sn\n",
    "from collections import Counter\n",
    "from gensim.sklearn_api.w2vmodel import W2VTransformer\n",
    "from gensim.sklearn_api.d2vmodel import D2VTransformer\n",
    "from itertools import chain\n",
    "from decimal import Decimal\n",
    "from IPython.display import display, HTML\n",
    "from ast import literal_eval\n",
    "import xlrd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'f1-scores': scores,\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer(\"dutch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Importing data\n",
    "df = pd.read_csv(\"Handelingen.csv\", index_col=0)\n",
    "df = df.loc[df['speech category'] == 'Main Speech']\n",
    "\n",
    "## FIX THIS INTO ONE LINE\n",
    "df['list_text'] = df.text.apply(lambda x: [stemmer.stem(t) for t in tokenizer.tokenize(x)])\n",
    "df['normal_text'] = df.list_text.apply(lambda x: ' '.join(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdf = df.party.value_counts()\n",
    "with open(\"Verslag/Spreekbeurten.tex\", \"w\") as f:\n",
    "    f.write(countdf.to_latex(header=False))\n",
    "countdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tekst = chain.from_iterable([list(set(doc)) for doc in df.list_text])\n",
    "count = Counter(tekst)\n",
    "samples = list(count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Counter(samples)\n",
    "t = sorted(t.items())\n",
    "x, y = zip(*t)\n",
    "plt.loglog(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tekst = [len(doc) for doc in df.list_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Counter(tekst)\n",
    "t = sorted(t.items())\n",
    "x, y = zip(*t)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelsdownload(only_doen=False):\n",
    "    models_df = pd.read_excel('Models.xlsx', index_col=0)\n",
    "    if only_doen:\n",
    "        models_df = models_df.loc[models_df.DOEN == True]\n",
    "    models_dict = {}\n",
    "    for x,y in zip(models_df.Classifier,models_df.PIPELINE):\n",
    "        exec(compile(\"a=\"+y,'','exec'),globals())\n",
    "        models_dict[x] = Pipeline(a)\n",
    "    return models_df, models_dict\n",
    "def modelsdownload2():\n",
    "    models_df = pd.read_excel('Models.xlsx', index_col=0)\n",
    "    models_dict = {}\n",
    "    for x,y in zip(models_df.Classifier,models_df.PIPELINE):\n",
    "        exec(compile(\"a=\"+y,'','exec'),globals())\n",
    "        models_dict[x] = Pipeline(a)\n",
    "    return models_df, models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df, models_dict = modelsdownload(True)\n",
    "    \n",
    "params_dict = {}\n",
    "for clf in set(models_df.Classifier):\n",
    "    params_df = models_df.loc[models_df.Classifier == clf]\n",
    "    params_df = params_df.loc[params_df.DOEN == True]\n",
    "    params_df = params_df.dropna(axis=1, how='all')\n",
    "    params_df = params_df.drop([col for col in params_df.columns if \"__\" not in col], axis =1)\n",
    "    temp_dict = {}\n",
    "    for x,y in params_df.to_dict(orient='list').items():\n",
    "        a = literal_eval(y[0])\n",
    "        temp_dict[x] = a   \n",
    "    params_dict[clf] = temp_dict\n",
    "    \n",
    "text_dict = {x:y for x,y in zip(models_df.Classifier, models_df.RAW)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,pipe in models_dict.items():\n",
    "    if text_dict[name]:\n",
    "         text = list(df.list_text)\n",
    "    else:\n",
    "        text = list(df.normal_text)\n",
    "    gs = GridSearchCV(pipe, params_dict[name], cv=5, scoring='f1_weighted')\n",
    "    gs.fit(text, df.party)\n",
    "    rows = [row(name, gsc.cv_validation_scores, gsc.parameters) for gsc in gs.grid_scores_]\n",
    "    df2 = pd.concat(rows, axis=1).T\n",
    "    pd.concat([df2, pd.read_csv('Scores.csv', index_col=0)], ignore_index=True).sort_values(['mean_score'], ascending=False).to_csv('Scores.csv')\n",
    "    df4 = pd.read_excel('Models.xlsx', index_col=0)\n",
    "    df4.loc[df.Classifier==name,\"DOEN\"] = False\n",
    "    df4.to_excel('Models.xlsx')\n",
    "    \n",
    "#https://stackoverflow.com/questions/46735847/save-best-params-in-gridsearch-in-a-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/36271413/pandas-merge-nearly-duplicate-rows-based-on-column-value?rq=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('Scores.csv', index_col=0).head(1)\n",
    "scores = scores.dropna(axis=1).reset_index(drop=True)\n",
    "scores.vect__ngram_range[0] = literal_eval(scores.vect__ngram_range[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df, models_dict = modelsdownload(False)\n",
    "pipe = models_dict[scores.estimator[0]]\n",
    "pipe.set_params(**scores.drop([col for col in scores.columns if \"__\" not in col], axis=1).to_dict(orient='records')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8)\n",
    "df_test_index = list(set(df.index.tolist()) - set(df_train.index.tolist()))\n",
    "df_test = df[df.index.isin(df_test_index)]\n",
    "pipe.fit(list(df_train.normal_text), list(df_train.party))\n",
    "predicted = pipe.predict(df_test.normal_text)\n",
    "print(classification_report(df_test.party, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "cnf_matrix = confusion_matrix(df_test.party, predicted)\n",
    "plot_confusion_matrix(cnf_matrix, \\\n",
    "                      classes=sorted(list(df.party.unique())), \\\n",
    "                      title='Confusion matrix best estimator')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull\n",
    "!git add CompleteNotebook.ipynb\n",
    "!git add Bestscore.ipynb\n",
    "!git add Scraper.ipynb\n",
    "!git add Scores.csv\n",
    "!git add Verslag/Scriptie_Sprekers_TK.pdf\n",
    "!git add Verslag/Spreekbeurten.tex\n",
    "!git add Verslag/MItable.tex\n",
    "!git add Models.xlsx\n",
    "!git commit -m Update\n",
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
